{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be887c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import keepsake\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6428385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only need to be run once to initialize\n",
    "\n",
    "# ! echo 'repository: \"file://.keepsake\"' > keepsake.yaml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "799d1ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acc_x|acc_y|acc_z|gyro_x|label',\n",
       " 'acc_x|acc_y|acc_z|gyro_y|label',\n",
       " 'acc_x|acc_y|acc_z|gyro_z|label',\n",
       " 'acc_x|acc_y|acc_z|gyro_x|gyro_y|label',\n",
       " 'acc_x|acc_y|acc_z|gyro_x|gyro_z|label',\n",
       " 'acc_x|acc_y|acc_z|gyro_y|gyro_z|label',\n",
       " 'acc_x|acc_y|acc_z|gyro_x|gyro_y|gyro_z|label']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate signal combinations\n",
    "from itertools import combinations\n",
    "\n",
    "comb_list = []\n",
    "\n",
    "for features in [1,2,3]:\n",
    "    for com in combinations(['gyro_x','gyro_y','gyro_z'], features):\n",
    "        comb_list.append(f'acc_x|acc_y|acc_z|{\"|\".join(list(com))}|label')\n",
    "comb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccf1a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_10hz = pd.read_csv('data/transformed/20210529_v2_data_all_10hz.csv') # not neede for experiments\n",
    "df_20hz = pd.read_csv('data/transformed/20210529_v2_data_all_20hz.csv')\n",
    "df_25hz = pd.read_csv('data/transformed/20210529_v2_data_all_25hz.csv')\n",
    "df_50hz = pd.read_csv('data/transformed/20210529_v2_data_all_50hz.csv')\n",
    "# df_100hz = pd.read_csv('data/transformed/20210529_v2_data_all_100hz.csv') # not neede for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab3f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_base(df):\n",
    "    '''Gets baseline dataset.'''\n",
    "    df = df[(df['shift'] == 0)]\n",
    "    return df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3cd507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20hz = get_df_base(df_20hz)\n",
    "df_25hz = get_df_base(df_25hz)\n",
    "df_50hz = get_df_base(df_50hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff79012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_optimized(classifier, stage, dataset, model_type, exp_id):\n",
    "    '''\n",
    "    Saves model to defined folder.\n",
    "    \n",
    "    Args:\n",
    "        stage: baseline/optimized\n",
    "        dataset: base/centered/end/etc\n",
    "        model_types: decision_tree, random_forest, ...\n",
    "        hz: frequency\n",
    "    Returns:\n",
    "        Saved file path.\n",
    "    '''\n",
    "\n",
    "    import os\n",
    "    import m2cgen as m2c\n",
    "    \n",
    "    BASE_PATH = f'models/{stage}/{dataset}/{model_type}/'\n",
    "    FILE_NAME = f'{model_type}_{exp_id}.py'\n",
    "\n",
    "    if not os.path.exists(BASE_PATH):\n",
    "        os.makedirs(BASE_PATH)\n",
    "\n",
    "    code = m2c.export_to_python(classifier)\n",
    "    with open(BASE_PATH + FILE_NAME, 'w') as f:\n",
    "        f.writelines(code)\n",
    "        \n",
    "    return BASE_PATH + FILE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61447ede",
   "metadata": {},
   "source": [
    "**Train Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ada12a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signals: ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y'] @ 20 >> Acc: 1.0, Prec: 1.0, Recall: 1.0\n",
      "Signals: ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y'] @ 20 >> Acc: 1.0, Prec: 1.0, Recall: 1.0\n",
      "Signals: ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y'] @ 20 >> Acc: 1.0, Prec: 1.0, Recall: 1.0\n",
      "Signals: ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_z'] @ 20 >> Acc: 1.0, Prec: 1.0, Recall: 1.0\n",
      "Signals: ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z'] @ 25 >> Acc: 0.9875, Prec: 0.984375, Recall: 0.9924242424242424\n",
      "Signals: ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z'] @ 25 >> Acc: 0.9875, Prec: 0.984375, Recall: 0.9924242424242424\n",
      "Signals: ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y'] @ 50 >> Acc: 1.0, Prec: 1.0, Recall: 1.0\n",
      "Signals: ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_z'] @ 50 >> Acc: 1.0, Prec: 1.0, Recall: 1.0\n",
      "Signals: ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z'] @ 50 >> Acc: 1.0, Prec: 1.0, Recall: 1.0\n",
      "Filtered experiments with accuracy == 1.0:\n",
      "{'model': 'random_forest', 'features': ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y'], 'feature_count': 5, 'n_estimators': 4, 'dataset_test_size': 0.35, 'hz': 20, 'data_set': 'base', 'quantization': None, 'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'model_path': './models/optimized/base/random_forest/random_forest_20_acc_x_acc_y_acc_z_gyro_x_gyro_y_4.py'}\n",
      "{'model': 'random_forest', 'features': ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y'], 'feature_count': 5, 'n_estimators': 5, 'dataset_test_size': 0.35, 'hz': 20, 'data_set': 'base', 'quantization': None, 'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'model_path': './models/optimized/base/random_forest/random_forest_20_acc_x_acc_y_acc_z_gyro_x_gyro_y_5.py'}\n",
      "{'model': 'random_forest', 'features': ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y'], 'feature_count': 5, 'n_estimators': 6, 'dataset_test_size': 0.35, 'hz': 20, 'data_set': 'base', 'quantization': None, 'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'model_path': './models/optimized/base/random_forest/random_forest_20_acc_x_acc_y_acc_z_gyro_x_gyro_y_6.py'}\n",
      "{'model': 'random_forest', 'features': ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_z'], 'feature_count': 5, 'n_estimators': 4, 'dataset_test_size': 0.35, 'hz': 20, 'data_set': 'base', 'quantization': None, 'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'model_path': './models/optimized/base/random_forest/random_forest_20_acc_x_acc_y_acc_z_gyro_x_gyro_z_4.py'}\n",
      "{'model': 'random_forest', 'features': ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y'], 'feature_count': 5, 'n_estimators': 6, 'dataset_test_size': 0.35, 'hz': 50, 'data_set': 'base', 'quantization': None, 'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'model_path': './models/optimized/base/random_forest/random_forest_50_acc_x_acc_y_acc_z_gyro_x_gyro_y_6.py'}\n",
      "{'model': 'random_forest', 'features': ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_z'], 'feature_count': 5, 'n_estimators': 6, 'dataset_test_size': 0.35, 'hz': 50, 'data_set': 'base', 'quantization': None, 'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'model_path': './models/optimized/base/random_forest/random_forest_50_acc_x_acc_y_acc_z_gyro_x_gyro_z_6.py'}\n",
      "{'model': 'random_forest', 'features': ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z'], 'feature_count': 6, 'n_estimators': 5, 'dataset_test_size': 0.35, 'hz': 50, 'data_set': 'base', 'quantization': None, 'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'model_path': './models/optimized/base/random_forest/random_forest_50_acc_x_acc_y_acc_z_gyro_x_gyro_y_gyro_z_5.py'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# Directory to store the models and experiments\n",
    "save_dir = './models/optimized/base/random_forest/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Clear earlier saved files\n",
    "for filename in os.listdir(save_dir):\n",
    "    file_path = os.path.join(save_dir, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error while deleting file {file_path}: {e}\")\n",
    "\n",
    "# Prepare for saving results\n",
    "results_file = './experiment_results.csv'\n",
    "columns = ['model', 'features', 'feature_count', 'n_estimators', 'dataset_test_size', 'hz', 'data_set', 'quantization', 'accuracy', 'precision', 'recall', 'f1', 'model_path']\n",
    "\n",
    "# Create or append to the results file\n",
    "if not os.path.exists(results_file):\n",
    "    df_results = pd.DataFrame(columns=columns)\n",
    "else:\n",
    "    df_results = pd.read_csv(results_file)\n",
    "\n",
    "is_save_model = True\n",
    "model_type = 'random_forest'\n",
    "stage = 'optimized'\n",
    "dataset = 'base'\n",
    "quantization = None\n",
    "estimators = None\n",
    "\n",
    "cutoff = 0.99\n",
    "dataset_test_sizes = [0.35]\n",
    "datasets_setup = [(df_20hz, 20), (df_25hz, 25), (df_50hz, 50)]\n",
    "\n",
    "experiment_results = []\n",
    "\n",
    "for df_t in datasets_setup:\n",
    "    for comb in comb_list:\n",
    "        for dataset_test_size in dataset_test_sizes:\n",
    "            df_filtered = df_t[0].filter(regex=comb)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                df_filtered.drop('label', axis=1), df_filtered['label'],\n",
    "                test_size=dataset_test_size, random_state=42)\n",
    "\n",
    "            for estimators in [4, 5, 6]:\n",
    "                clf = RandomForestClassifier(n_jobs=-1, n_estimators=estimators, random_state=42)\n",
    "                clf.fit(X_train, y_train)\n",
    "\n",
    "                y_pred = clf.predict(X_test)\n",
    "\n",
    "                accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "                f1 = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "                precision = metrics.precision_score(y_test, y_pred, average='macro')\n",
    "                recall = metrics.recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "                if recall > cutoff:\n",
    "                    signals = comb.replace('|label', '').split('|')\n",
    "                    print(f\"Signals: {signals} @ {df_t[1]} >> Acc: {accuracy}, Prec: {precision}, Recall: {recall}\")\n",
    "\n",
    "                    if is_save_model:\n",
    "                        # Generate shorter model file name based on dataset and signals\n",
    "                        signal_str = \"_\".join(signals)\n",
    "                        model_filename = f\"random_forest_{df_t[1]}_{signal_str}_{estimators}.py\"\n",
    "                        model_path = os.path.join(save_dir, model_filename)\n",
    "\n",
    "                        # Create the Python code for the model\n",
    "                        model_code = f\"\"\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "\n",
    "def create_model():\n",
    "    clf = RandomForestClassifier(n_jobs=-1, n_estimators={estimators}, random_state=42)\n",
    "    return clf\n",
    "\n",
    "def evaluate_model(clf, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "    precision = metrics.precision_score(y_test, y_pred, average='macro')\n",
    "    recall = metrics.recall_score(y_test, y_pred, average='macro')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    clf = create_model()\n",
    "    accuracy, precision, recall, f1 = evaluate_model(clf, X_train, X_test, y_train, y_test)\n",
    "    print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1: {f1}\")\n",
    "\"\"\"\n",
    "                        # Save the Python code as a .py file\n",
    "                        with open(model_path, 'w') as f:\n",
    "                            f.write(model_code)\n",
    "\n",
    "                        # Store the experiment result in a dictionary\n",
    "                        experiment_result = {\n",
    "                            'model': model_type,\n",
    "                            'features': signals,\n",
    "                            'feature_count': len(signals),\n",
    "                            'n_estimators': estimators,\n",
    "                            'dataset_test_size': dataset_test_size,\n",
    "                            'hz': df_t[1],\n",
    "                            'data_set': dataset,\n",
    "                            'quantization': quantization,\n",
    "                            'accuracy': accuracy,\n",
    "                            'precision': precision,\n",
    "                            'recall': recall,\n",
    "                            'f1': f1,\n",
    "                            'model_path': model_path\n",
    "                        }\n",
    "\n",
    "                        # Add the result to the list for later use\n",
    "                        experiment_results.append(experiment_result)\n",
    "\n",
    "                        # Save each experiment's result separately in the CSV\n",
    "                        df_results = pd.concat([df_results, pd.DataFrame([experiment_result])], ignore_index=True)\n",
    "\n",
    "# Save the results to CSV\n",
    "df_results.to_csv(results_file, index=False)\n",
    "\n",
    "# You can print or analyze the experiment results if needed\n",
    "print(\"Filtered experiments with accuracy == 1.0:\")\n",
    "filtered_results = [exp for exp in experiment_results if exp['accuracy'] == 1.0]\n",
    "for result in filtered_results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470a0bc3",
   "metadata": {},
   "source": [
    "**Train Desicion Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18b1cb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signals: ['acc_x', 'acc_y', 'acc_z', 'gyro_x'] @ 25 >> Acc: 1.0, Prec: 1.0, Recall: 1.0\n",
      "Signals: ['acc_x', 'acc_y', 'acc_z', 'gyro_y'] @ 25 >> Acc: 1.0, Prec: 1.0, Recall: 1.0\n",
      "Signals: ['acc_x', 'acc_y', 'acc_z', 'gyro_z'] @ 25 >> Acc: 1.0, Prec: 1.0, Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "import joblib  # Used for saving the model\n",
    "\n",
    "# Custom CSV logger function\n",
    "def log_experiment_csv(params, metrics, stage, dataset, model_type):\n",
    "    log_dir = \"logs\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    filename = f\"{log_dir}/exp_log_{stage}_{dataset}_{model_type}.csv\"\n",
    "\n",
    "    log_data = {**params, **metrics}\n",
    "\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    with open(filename, mode=\"a\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=log_data.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(log_data)\n",
    "\n",
    "# Save the model (function to save your model)\n",
    "def save_model_optimized(model, stage, dataset, model_type, exp_id):\n",
    "    model_dir = f\"models/{stage}/{dataset}/{model_type}/\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model_filename = f\"{model_dir}/{exp_id}.pkl\"\n",
    "    joblib.dump(model, model_filename)\n",
    "    return model_filename\n",
    "\n",
    "# Main experiment logic\n",
    "is_save_model = True\n",
    "model_type = 'decision_tree'\n",
    "stage = 'optimized'\n",
    "dataset = 'base'\n",
    "quantization = None\n",
    "cutoff = 0.99\n",
    "dataset_test_sizes = [0.35]\n",
    "datasets_setup = [(df_20hz, 20), (df_25hz, 25), (df_50hz, 50)]\n",
    "\n",
    "for df_t in datasets_setup:\n",
    "    for comb in comb_list:\n",
    "        for dataset_test_size in dataset_test_sizes:\n",
    "            # Filter the dataset based on the signal combination\n",
    "            df_filtered = df_t[0].filter(regex=comb)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                df_filtered.drop('label', axis=1), df_filtered['label'],\n",
    "                test_size=dataset_test_size, random_state=42)\n",
    "\n",
    "            # Create and train the Decision Tree model\n",
    "            clf = DecisionTreeClassifier(random_state=42)\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            # Predict and calculate metrics\n",
    "            y_pred = clf.predict(X_test)\n",
    "\n",
    "            accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "            f1 = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "            precision = metrics.precision_score(y_test, y_pred, average='macro')\n",
    "            recall = metrics.recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "            # Only log and save the model if recall exceeds the cutoff\n",
    "            if recall > cutoff:\n",
    "                signals = comb.replace('|label', '').split('|')\n",
    "                print(f\"Signals: {signals} @ {df_t[1]} >> Acc: {accuracy}, Prec: {precision}, Recall: {recall}\")\n",
    "\n",
    "                if is_save_model:\n",
    "                    exp_id = f\"{model_type}_{df_t[1]}hz\"\n",
    "                    params = {\n",
    "                        'exp_id': exp_id,\n",
    "                        'model': model_type,\n",
    "                        'features': signals,\n",
    "                        'feature_count': len(signals),\n",
    "                        'dataset_test_size': dataset_test_size,\n",
    "                        'hz': df_t[1],\n",
    "                        'data_set': dataset,\n",
    "                        'quantization': quantization,\n",
    "                        'other_params': 'default'\n",
    "                    }\n",
    "\n",
    "                    metrics_dict = {\n",
    "                        'accuracy': accuracy,\n",
    "                        'precision': precision,\n",
    "                        'recall': recall,\n",
    "                        'f1': f1\n",
    "                    }\n",
    "\n",
    "                    # Save the trained model\n",
    "                    path = save_model_optimized(clf, stage, dataset, model_type, exp_id)\n",
    "                    params['saved_model_path'] = path\n",
    "\n",
    "                    # Log the experiment to the CSV file\n",
    "                    log_experiment_csv(params, metrics_dict, stage, dataset, model_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a48e5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signals: ['acc_x', 'acc_y', 'acc_z', 'gyro_x'] @ 25 >> Acc: 1.0, Prec: 1.0, Recall: 1.0\n",
      "Signals: ['acc_x', 'acc_y', 'acc_z', 'gyro_y'] @ 25 >> Acc: 1.0, Prec: 1.0, Recall: 1.0\n",
      "Signals: ['acc_x', 'acc_y', 'acc_z', 'gyro_z'] @ 25 >> Acc: 1.0, Prec: 1.0, Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "import joblib  # Used for saving the model\n",
    "\n",
    "# Custom CSV logger function\n",
    "def log_experiment_csv(params, metrics, stage, dataset, model_type, exp_id):\n",
    "    log_dir = \"logs\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    filename = f\"{log_dir}/exp_log_{exp_id}.csv\"  # Separate file per experiment using exp_id\n",
    "\n",
    "    log_data = {**params, **metrics}\n",
    "\n",
    "    # Writing experiment results to the separate file\n",
    "    with open(filename, mode=\"w\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=log_data.keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerow(log_data)\n",
    "\n",
    "# Save the model (function to save your model)\n",
    "def save_model_optimized(model, stage, dataset, model_type, exp_id):\n",
    "    model_dir = f\"models/{stage}/{dataset}/{model_type}/\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model_filename = f\"{model_dir}/{exp_id}.pkl\"\n",
    "    joblib.dump(model, model_filename)\n",
    "    return model_filename\n",
    "\n",
    "# Main experiment logic\n",
    "is_save_model = True\n",
    "model_type = 'decision_tree'\n",
    "stage = 'optimized'\n",
    "dataset = 'base'\n",
    "quantization = None\n",
    "cutoff = 0.99\n",
    "dataset_test_sizes = [0.35]\n",
    "datasets_setup = [(df_20hz, 20), (df_25hz, 25), (df_50hz, 50)]\n",
    "\n",
    "for df_t in datasets_setup:\n",
    "    for comb in comb_list:\n",
    "        for dataset_test_size in dataset_test_sizes:\n",
    "            # Filter the dataset based on the signal combination\n",
    "            df_filtered = df_t[0].filter(regex=comb)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                df_filtered.drop('label', axis=1), df_filtered['label'],\n",
    "                test_size=dataset_test_size, random_state=42)\n",
    "\n",
    "            # Create and train the Decision Tree model\n",
    "            clf = DecisionTreeClassifier(random_state=42)\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            # Predict and calculate metrics\n",
    "            y_pred = clf.predict(X_test)\n",
    "\n",
    "            accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "            f1 = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "            precision = metrics.precision_score(y_test, y_pred, average='macro')\n",
    "            recall = metrics.recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "            # Only log and save the model if recall exceeds the cutoff\n",
    "            if recall > cutoff:\n",
    "                signals = comb.replace('|label', '').split('|')\n",
    "                print(f\"Signals: {signals} @ {df_t[1]} >> Acc: {accuracy}, Prec: {precision}, Recall: {recall}\")\n",
    "\n",
    "                if is_save_model:\n",
    "                    exp_id = f\"{model_type}_{df_t[1]}hz_{'_'.join(signals)}\"\n",
    "                    params = {\n",
    "                        'exp_id': exp_id,\n",
    "                        'model': model_type,\n",
    "                        'features': signals,\n",
    "                        'feature_count': len(signals),\n",
    "                        'dataset_test_size': dataset_test_size,\n",
    "                        'hz': df_t[1],\n",
    "                        'data_set': dataset,\n",
    "                        'quantization': quantization,\n",
    "                        'other_params': 'default'\n",
    "                    }\n",
    "\n",
    "                    metrics_dict = {\n",
    "                        'accuracy': accuracy,\n",
    "                        'precision': precision,\n",
    "                        'recall': recall,\n",
    "                        'f1': f1\n",
    "                    }\n",
    "\n",
    "                    # Save the trained model\n",
    "                    path = save_model_optimized(clf, stage, dataset, model_type, exp_id)\n",
    "                    params['saved_model_path'] = path\n",
    "\n",
    "                    # Log the experiment to the CSV file (separate file per experiment)\n",
    "                    log_experiment_csv(params, metrics_dict, stage, dataset, model_type, exp_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91876bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exp_id': 'random_forest_4_20hz', 'model': 'random_forest', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y']\", 'feature_count': '5', 'n_estimators': '4', 'dataset_test_size': '0.35', 'hz': '20', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/inf_time_test/random_forest/optimized/base\\\\random_forest_random_forest_4_20hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'random_forest_5_20hz', 'model': 'random_forest', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y']\", 'feature_count': '5', 'n_estimators': '5', 'dataset_test_size': '0.35', 'hz': '20', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/inf_time_test/random_forest/optimized/base\\\\random_forest_random_forest_5_20hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'random_forest_6_20hz', 'model': 'random_forest', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y']\", 'feature_count': '5', 'n_estimators': '6', 'dataset_test_size': '0.35', 'hz': '20', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/inf_time_test/random_forest/optimized/base\\\\random_forest_random_forest_6_20hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'random_forest_4_20hz', 'model': 'random_forest', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_z']\", 'feature_count': '5', 'n_estimators': '4', 'dataset_test_size': '0.35', 'hz': '20', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/inf_time_test/random_forest/optimized/base\\\\random_forest_random_forest_4_20hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'random_forest_6_50hz', 'model': 'random_forest', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y']\", 'feature_count': '5', 'n_estimators': '6', 'dataset_test_size': '0.35', 'hz': '50', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/inf_time_test/random_forest/optimized/base\\\\random_forest_random_forest_6_50hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'random_forest_6_50hz', 'model': 'random_forest', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_z']\", 'feature_count': '5', 'n_estimators': '6', 'dataset_test_size': '0.35', 'hz': '50', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/inf_time_test/random_forest/optimized/base\\\\random_forest_random_forest_6_50hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'random_forest_5_50hz', 'model': 'random_forest', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']\", 'feature_count': '6', 'n_estimators': '5', 'dataset_test_size': '0.35', 'hz': '50', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/inf_time_test/random_forest/optimized/base\\\\random_forest_random_forest_5_50hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'random_forest_4_20hz', 'model': 'random_forest', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y']\", 'feature_count': '5', 'n_estimators': '4', 'dataset_test_size': '0.35', 'hz': '20', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/inf_time_test/random_forest/optimized/base\\\\random_forest_random_forest_4_20hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'random_forest_5_20hz', 'model': 'random_forest', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y']\", 'feature_count': '5', 'n_estimators': '5', 'dataset_test_size': '0.35', 'hz': '20', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/inf_time_test/random_forest/optimized/base\\\\random_forest_random_forest_5_20hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'random_forest_6_20hz', 'model': 'random_forest', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y']\", 'feature_count': '5', 'n_estimators': '6', 'dataset_test_size': '0.35', 'hz': '20', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/inf_time_test/random_forest/optimized/base\\\\random_forest_random_forest_6_20hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'random_forest_4_20hz', 'model': 'random_forest', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_z']\", 'feature_count': '5', 'n_estimators': '4', 'dataset_test_size': '0.35', 'hz': '20', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/inf_time_test/random_forest/optimized/base\\\\random_forest_random_forest_4_20hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'random_forest_6_50hz', 'model': 'random_forest', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y']\", 'feature_count': '5', 'n_estimators': '6', 'dataset_test_size': '0.35', 'hz': '50', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/inf_time_test/random_forest/optimized/base\\\\random_forest_random_forest_6_50hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'random_forest_6_50hz', 'model': 'random_forest', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_z']\", 'feature_count': '5', 'n_estimators': '6', 'dataset_test_size': '0.35', 'hz': '50', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/inf_time_test/random_forest/optimized/base\\\\random_forest_random_forest_6_50hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'random_forest_5_50hz', 'model': 'random_forest', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']\", 'feature_count': '6', 'n_estimators': '5', 'dataset_test_size': '0.35', 'hz': '50', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/inf_time_test/random_forest/optimized/base\\\\random_forest_random_forest_5_50hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'random_forest_4_20hz', 'model': 'random_forest', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y']\", 'feature_count': '5', 'n_estimators': '4', 'dataset_test_size': '0.35', 'hz': '20', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/optimized/base/random_forest/random_forest_random_forest_4_20hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'random_forest_5_20hz', 'model': 'random_forest', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y']\", 'feature_count': '5', 'n_estimators': '5', 'dataset_test_size': '0.35', 'hz': '20', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/optimized/base/random_forest/random_forest_random_forest_5_20hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'random_forest_6_20hz', 'model': 'random_forest', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y']\", 'feature_count': '5', 'n_estimators': '6', 'dataset_test_size': '0.35', 'hz': '20', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/optimized/base/random_forest/random_forest_random_forest_6_20hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'random_forest_4_20hz', 'model': 'random_forest', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_z']\", 'feature_count': '5', 'n_estimators': '4', 'dataset_test_size': '0.35', 'hz': '20', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/optimized/base/random_forest/random_forest_random_forest_4_20hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'random_forest_6_50hz', 'model': 'random_forest', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y']\", 'feature_count': '5', 'n_estimators': '6', 'dataset_test_size': '0.35', 'hz': '50', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/optimized/base/random_forest/random_forest_random_forest_6_50hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'random_forest_6_50hz', 'model': 'random_forest', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_z']\", 'feature_count': '5', 'n_estimators': '6', 'dataset_test_size': '0.35', 'hz': '50', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/optimized/base/random_forest/random_forest_random_forest_6_50hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'random_forest_5_50hz', 'model': 'random_forest', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']\", 'feature_count': '6', 'n_estimators': '5', 'dataset_test_size': '0.35', 'hz': '50', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/optimized/base/random_forest/random_forest_random_forest_5_50hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Function to filter experiments\n",
    "def filter_experiments(log_dir, accuracy=1.0, model='random_forest'):\n",
    "    matching_experiments = []\n",
    "    for filename in os.listdir(log_dir):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(log_dir, filename)\n",
    "            with open(file_path, mode='r', newline='') as f:\n",
    "                reader = csv.DictReader(f)\n",
    "                for row in reader:\n",
    "                    if float(row['accuracy']) == accuracy and row['model'] == model:\n",
    "                        matching_experiments.append(row)\n",
    "    return matching_experiments\n",
    "\n",
    "# Example usage\n",
    "log_dir = \"logs\"  # Directory where logs are stored\n",
    "filtered_experiments = filter_experiments(log_dir)\n",
    "\n",
    "# Print the matching experiments\n",
    "for exp in filtered_experiments:\n",
    "    print(exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fba42e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exp_id': 'decision_tree_25hz', 'model': 'decision_tree', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x']\", 'feature_count': '4', 'dataset_test_size': '0.35', 'hz': '25', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/optimized/base/decision_tree/decision_tree_decision_tree_25hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'decision_tree_25hz', 'model': 'decision_tree', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_y']\", 'feature_count': '4', 'dataset_test_size': '0.35', 'hz': '25', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/optimized/base/decision_tree/decision_tree_decision_tree_25hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'decision_tree_25hz', 'model': 'decision_tree', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_z']\", 'feature_count': '4', 'dataset_test_size': '0.35', 'hz': '25', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/optimized/base/decision_tree/decision_tree_decision_tree_25hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'decision_tree_25hz', 'model': 'decision_tree', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x']\", 'feature_count': '4', 'dataset_test_size': '0.35', 'hz': '25', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/optimized/base/decision_tree/decision_tree_decision_tree_25hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'decision_tree_25hz', 'model': 'decision_tree', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_y']\", 'feature_count': '4', 'dataset_test_size': '0.35', 'hz': '25', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/optimized/base/decision_tree/decision_tree_decision_tree_25hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'decision_tree_25hz', 'model': 'decision_tree', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_z']\", 'feature_count': '4', 'dataset_test_size': '0.35', 'hz': '25', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/optimized/base/decision_tree/decision_tree_decision_tree_25hz.py', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'decision_tree_25hz', 'model': 'decision_tree', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x']\", 'feature_count': '4', 'dataset_test_size': '0.35', 'hz': '25', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/optimized/base/decision_tree//decision_tree_25hz.pkl', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'decision_tree_25hz', 'model': 'decision_tree', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_y']\", 'feature_count': '4', 'dataset_test_size': '0.35', 'hz': '25', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/optimized/base/decision_tree//decision_tree_25hz.pkl', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'decision_tree_25hz', 'model': 'decision_tree', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_z']\", 'feature_count': '4', 'dataset_test_size': '0.35', 'hz': '25', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/optimized/base/decision_tree//decision_tree_25hz.pkl', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'decision_tree_25hz', 'model': 'decision_tree', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_x']\", 'feature_count': '4', 'dataset_test_size': '0.35', 'hz': '25', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/optimized/base/decision_tree//decision_tree_25hz.pkl', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'decision_tree_25hz', 'model': 'decision_tree', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_y']\", 'feature_count': '4', 'dataset_test_size': '0.35', 'hz': '25', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/optimized/base/decision_tree//decision_tree_25hz.pkl', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n",
      "{'exp_id': 'decision_tree_25hz', 'model': 'decision_tree', 'features': \"['acc_x', 'acc_y', 'acc_z', 'gyro_z']\", 'feature_count': '4', 'dataset_test_size': '0.35', 'hz': '25', 'data_set': 'base', 'quantization': '', 'other_params': 'default', 'saved_model_path': 'models/optimized/base/decision_tree//decision_tree_25hz.pkl', 'accuracy': '1.0', 'precision': '1.0', 'recall': '1.0', 'f1': '1.0'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Function to filter experiments based on accuracy and model type\n",
    "def filter_experiments_by_model(log_dir, accuracy=1.0, model='decision_tree'):\n",
    "    matching_experiments = []\n",
    "    for filename in os.listdir(log_dir):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(log_dir, filename)\n",
    "            with open(file_path, mode='r', newline='') as f:\n",
    "                reader = csv.DictReader(f)\n",
    "                for row in reader:\n",
    "                    if float(row['accuracy']) == accuracy and row['model'] == model:\n",
    "                        matching_experiments.append(row)\n",
    "    return matching_experiments\n",
    "\n",
    "# Example usage\n",
    "log_dir = \"logs\"  # Directory where logs are stored\n",
    "filtered_experiments = filter_experiments_by_model(log_dir)\n",
    "\n",
    "# Print the matching experiments\n",
    "for exp in filtered_experiments:\n",
    "    print(exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0f062f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signals: ['acc_x', 'acc_y', 'acc_z', 'gyro_x'] @ 25Hz >> Acc: 1.00, Prec: 1.00, Recall: 1.00\n",
      "Signals: ['acc_x', 'acc_y', 'acc_z', 'gyro_y'] @ 25Hz >> Acc: 1.00, Prec: 1.00, Recall: 1.00\n",
      "Signals: ['acc_x', 'acc_y', 'acc_z', 'gyro_z'] @ 25Hz >> Acc: 1.00, Prec: 1.00, Recall: 1.00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import m2cgen as m2c  # Changed from joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# Custom CSV logger function (unchanged)\n",
    "def log_experiment_csv(params, metrics, stage, dataset, model_type):\n",
    "    log_dir = \"logs\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    filename = f\"{log_dir}/exp_log_{stage}_{dataset}_{model_type}.csv\"\n",
    "\n",
    "    log_data = {**params, **metrics}\n",
    "\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    with open(filename, mode=\"a\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=log_data.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(log_data)\n",
    "\n",
    "# Modified save function to use m2cgen\n",
    "def save_model_optimized(model, stage, dataset, model_type, exp_id):\n",
    "    model_dir = f\"models/{stage}/{dataset}/{model_type}/\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model_filename = f\"{model_dir}/{exp_id}.py\"  # Changed to .py\n",
    "    \n",
    "    # Convert model to Python code\n",
    "    py_code = m2c.export_to_python(model)\n",
    "    \n",
    "    with open(model_filename, 'w') as f:\n",
    "        f.write(py_code)\n",
    "    \n",
    "    return model_filename\n",
    "\n",
    "# Main experiment logic (modified exp_id)\n",
    "is_save_model = True\n",
    "model_type = 'decision_tree'\n",
    "stage = 'optimized'\n",
    "dataset = 'base'\n",
    "quantization = None\n",
    "cutoff = 0.99\n",
    "dataset_test_sizes = [0.35]\n",
    "datasets_setup = [(df_20hz, 20), (df_25hz, 25), (df_50hz, 50)]\n",
    "\n",
    "for df_t in datasets_setup:\n",
    "    df, hz = df_t  # Unpack tuple for clarity\n",
    "    for comb in comb_list:\n",
    "        for dataset_test_size in dataset_test_sizes:\n",
    "            # Filter the dataset based on the signal combination\n",
    "            df_filtered = df.filter(regex=comb)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                df_filtered.drop('label', axis=1), df_filtered['label'],\n",
    "                test_size=dataset_test_size, random_state=42)\n",
    "\n",
    "            # Create and train the Decision Tree model\n",
    "            clf = DecisionTreeClassifier(random_state=42)\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            # Predict and calculate metrics\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "            f1 = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "            precision = metrics.precision_score(y_test, y_pred, average='macro')\n",
    "            recall = metrics.recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "            if recall > cutoff:\n",
    "                signals = comb.replace('|label', '').split('|')\n",
    "                print(f\"Signals: {signals} @ {hz}Hz >> Acc: {accuracy:.2f}, Prec: {precision:.2f}, Recall: {recall:.2f}\")\n",
    "\n",
    "                if is_save_model:\n",
    "                    # Generate unique experiment ID with frequency and signals\n",
    "                    exp_id = f\"{model_type}_{hz}hz_{'_'.join(signals)}\"\n",
    "                    \n",
    "                    params = {\n",
    "                        'exp_id': exp_id,\n",
    "                        'model': model_type,\n",
    "                        'features': signals,\n",
    "                        'feature_count': len(signals),\n",
    "                        'dataset_test_size': dataset_test_size,\n",
    "                        'hz': hz,\n",
    "                        'data_set': dataset,\n",
    "                        'quantization': quantization,\n",
    "                        'other_params': 'default'\n",
    "                    }\n",
    "\n",
    "                    metrics_dict = {\n",
    "                        'accuracy': accuracy,\n",
    "                        'precision': precision,\n",
    "                        'recall': recall,\n",
    "                        'f1': f1\n",
    "                    }\n",
    "\n",
    "                    # Save as Python file\n",
    "                    path = save_model_optimized(clf, stage, dataset, model_type, exp_id)\n",
    "                    params['saved_model_path'] = path\n",
    "\n",
    "                    # Log the experiment\n",
    "                    log_experiment_csv(params, metrics_dict, stage, dataset, model_type)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
